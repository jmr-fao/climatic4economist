---
title: "SPI for the Afghanistan villages"
author: "JMR"
toc: true
toc-expand: 1
toc-depth: 3
format:
  html:
    self-contained: true
    code-tools: true
    toc-location: right-body
  docx: 
    toc-location: body
editor: source
editor_options:
  chunk_output_type: console
vignette: >
  %\VignetteIndexEntry{Vignette's Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
---

## Introduction
This guide provides a step-by-step approach to compute the Standardized Precipitation Index (SPI) based on village locations. 

## What do I need before starting?

The following R packages are necessary: `tidyverse`, `haven`, `SPEI`, `furrr`, `clock` and `terra`. To install the above package you can use `install.packages("name_of_package")`, don't forget the `"`. You also need the package `climatic4economist` which must be installed locally.

If you are not familiar with R check the [appendix] for understanding some coding style used in this tutorial.

## Code
### Set Up

In the setup, we create the paths to the various data sources and load the necessary functions for extraction. Note `..` means one step back to the folder directory, i.e. one folder back.

```{r set_up}
#| label: set_up

path_to_data <- file.path(#"..",
                          "..", "data")

path_to_tpr <- file.path(path_to_data, "weather", "ERA5_Land", 
                         "AFG", "monthly", "monthly_tpr_1970_2024")
path_to_tpr <- file.path(path_to_data, "weather", "ERA5_Land", 
                         "AFG", "monthly", "month_50_25_2m_tpr.nc")
path_to_village <- file.path(path_to_data, "survey", "AFG",
                             "Village coordinates_CoF(Village level coordinates).csv")

path_to_adm_div <- file.path(path_to_data, "adm_div", "UN_borders", "UN-AFG-ADM2.gpkg")

path_to_result <- file.path(path_to_data, "result")

```

We load also the package `climatic4economist` wich contains a series of wrapped functions to ease the computation.

```{r package}
#| label: package

library(climatic4economist)
```


### Load the data
#### Weather data
Let's start by loading the data into R. We load the weather observation with the function `terra::rast()`. As the raw data is made of two different files, we first load each one and then we combine with `c()` function.

```{r read_weather}
#| label: read_weather

# tpr_0 <- terra::rast(file.path(path_to_tpr, "data_0.nc"))
# tpr_1 <- terra::rast(file.path(path_to_tpr, "data_1.nc"))
# tpr_all <- c(tpr_0, tpr_1)

tpr_all <- terra::rast(path_to_tpr)

```

Note that there is no metadata for the time of the observations. We have this information in the names of the raster layers.

```{r time}
#| label: time
terra::time(tpr_all) |> head()
names(tpr_all) |> head()
```

However, the information is not ready to be used as it indicates seconds from 1970 (indeed the first observation have a negative sign as they refer to date before 1970).

We need to change the seconds into proper dates and set the names of the layers as the date of observation. This is very important for later.

Note that the layers are not correctly ordered, we change this with the function `tidyterra::relocate()`.

```{r second_to_date}
#| label: second_to_date

reference_period <- second_to_date(names(tpr_all))
reference_period |> tail()
reference_period |> head()

names(tpr_all) <- reference_period
tpr_all
```

#### Village locations
Now we load the villages. We rename the variable for easier use.

```{r read_villages}
#| label: read_villages

village <- data.table::fread(path_to_village) |> 
    dplyr::rename(lon = "Longitude (X)",
                  lat = "Latitude (Y)")
village
```

We load also the administrative divisions to check where the villages are.

```{r read_adm_div}
#| label: read_ad_div

adm_div <- terra::vect(path_to_adm_div)
adm_div
```

### Georeference the village

As we've mentioned, the weather data is georeferenced, so we need to ensure the same for the village data. 

>It is very important to check if the village and the raster data share the same coordinate reference system!

Usually, the WGS 84 CRS is the default coordinate references system for coordinates. In this case it  matches the weather coordinate references system.

We also need to ensure that we can later associate the correct weather data with the right village, we do this by creating a merging variable called `ID`. This is handled by the `prepare_coord()` function, which requires the coordinates' variable names as input.

```{r prepare_coord}
#| label: prepare_coord

village_coord <- prepare_coord(village,
                               lon_var = lon,
                               lat_var = lat)
village_coord
```

Once we have the unique coordinates, we are ready to transform them into spatial points using the `georef_coord()` function. When performing this transformation, it's crucial to set the correct CRS, which must match that of the weather data. The function also the coordinates' variable names as input.

```{r georef_coord}
#| label: georef_coord
village_geo <- georef_coord(village_coord,
                            geom = c("lon", "lat"),
                            crs = "EPSG:4326")
village_geo
```


### Plot
A good practice when working with spatial data is to plot it. This is the best way to verify that everything is working as expected.

First, we plot the administrative division and the villages to ensure they are correctly located and we examine their spatial distribution. 

```{r plot_survey_geo}
#| label: plot_survey_geo

terra::plot(adm_div, 
            col = "grey80",
            border="grey60",
            lwd = 0.1,
            main = "Afganistan's District and Programme Villages")
terra::points(village_geo, col = "blue", cex = 1)

village_geo |> 
    tidyterra::filter(ID == 47) |> 
    terra::text("ID", col = "red")
```

We can see that the village `ID == 47` is isolated fro the other villages, which tend to cluster in two distinct areas. I would suggest to double check the accuracy of this village.

```{r oulier}
#| label: oulier

village_coord |> 
    dplyr::filter(ID == 47) |> 
    knitr::kable()
```

Next, we plot a layer of the monthly precipitation data to see how it overlaps with the spatial coordinates.

```{r plot_precipitation}
#| label: plot_precipitation

terra::plot(tpr_all, "2023-12-01", col = terra::map.pal("water"),
            main = "Monthly precipitation on 2023-12-01 and village locations")
terra::points(village_geo, col = "gold", cex = 0.8)
```

Once again, the villages coordinates align with the temperature data, which is great!

### Extract
Next, we extract the weather data based on the village coordinates using the `extract_by_coord()` function. This function requires the raster with the weather data and the georeferenced coordinates as inputs.

Looking at the result, we see first the `ID` column, that identifies the village coordinates. The second and third column are the coordinates of the associated cells.

```{r extract_tmin}
#| label: extract_tmin

tpre_village_m <- extract_by_coord(raster = tpr_all, 
                                   coord = village_geo)
tpre_village_m

```

Again we have a row for each unique village. However, if we want to know how many different cells there are we can look unique cell coordinates.

```{r cell_coordinate}
#| label: cell_coordinate

unique_cell <- tpre_village_m |>
  dplyr::distinct(x_cell, y_cell)
nrow(unique_cell)
```

We see that now the number of rows is `r nrow(unique_cell)`, this is the actual different weather observation that we can merge with the villages. In other words, many villages share the same weather observation as they fall within the same pixel.


### Prepare data
The original unit of measure is in meters, we change it into milliliters to ease the interpretation.

```{r transformation}
#| label: transformation

tpre_village_mm <- tpre_village_m |>
  dplyr::mutate(dplyr::across(.cols = dplyr::matches("[0-9]{4}"),
                              .fns = ~ .x *1000))
```


### Compute the SPI
We now compute the SPI with the function `compute_spi()`. This function requires the precipitation time series for each location and the time scale at which the SPI is computed.

To compute the SPI, it is recommended to use at least 30 years of observation to ensure a good estimation of the parameters. More years can strength the estimation but the results can be affected by climate change: if there have been a change in the climate parameters, old observations might be not indicative of the current situation affecting the estimation. There are no clear rule on this, so we leave the possibility to select the time range of observation with the function `select_by_dates()`.

The function `select_by_dates()` requires both or just one between the starting date, `from`, and the end date `to`. If both are provide the the function select between the two dates, if only `from` is provided the function selects all date after, and if only `to` is provided the function selects all date before. To know more look for the help page or run `?select_by_dates`.

Looking at the result, we see first is the `ID` column, that we will use to merge back with the survey. The other columns contain the SPI observations over time specific to each coordinate.

```{r compute_spi1}
#| label: compute_spi1
#| warning: false

spi1 <- compute_spi(tpre_village_mm, time_scale = 1)
spi1
```

When we select a time scale grater than one, we can see that the first observations are missing, this is because the SPI left average the months indicated by the time scale.

```{r compute_spi}
#| label: compute_spi
#| warning: false

spi3 <- compute_spi(tpre_village_mm, time_scale = 3)
spi3
```

### Merge with survey
Now, we combine the extracted weather data with the village data using `ID` as the key matching variable.

If we want to select just a subsets of observations we can use the `select_by_dates()` function. 

If we want to select based on the date of interview of the survey, we can use `select_by_interview()`.

```{r merge_spi}
#| label: merge_spi

spi3_village <- merge_with_survey(village_coord, spi3)
spi3_village_22_24 <- select_by_interview(df = spi3_village,
                                          interview = "2024-09-21",
                                          interval = "2 year")
spi3_village_22_24

spi1_village <- merge_with_survey(village_coord, spi1)
spi1_village_22_24 <- select_by_interview(df = spi1_village,
                                          interview = "2024-09-21",
                                          interval = "2 year")
spi1_village_22_24
```


### Save

The final step of the code is to save the result. In this case, we save it as a `dta` file using the `haven::write_dta()` function. Then we need to  align the variables' name to the STATA format with the function `to_stata_format()`. We also remove the fifth column as the name cannot be aligned with the STATA format, and finally we save the result.

```{r write_data}
#| label: write_data

spi1_village_22_24 |> 
  dplyr::select(-dplyr::starts_with("Treatment")) |> 
  dplyr::rename_with(to_stata_format) |>
  haven::write_dta(file.path(path_to_result, "afg_village_spi1.dta"))

spi3_village_22_24 |> 
  dplyr::select(-dplyr::starts_with("Treatment")) |> 
  dplyr::rename_with(to_stata_format) |>
  haven::write_dta(file.path(path_to_result, "afg_village_spi3.dta"))

```

## Appendix
### New to R? Read this first!
#### The pipe command

The pipe command `|>`. It lets you pass the result of one expression as the first argument to the next. It creates a fluid chain of functions.

Instead of nesting functions inside each other, you can pipe the output forward, making the code easier to read.

```{r}
4 |> log() |> exp()

exp(log(4))
```

Note:

* The base R pipe `|>` was introduced in R 4.1.0.

* In some tutorials, you might also see `%>%`, which comes from the `magrittr` or `dplyr` packages. Both do a similar thing, but `|>` is now the official base R version.

#### The package namespaces
In R, namespaces help organize functions inside packages.

You can use a function from a specific package by writing: `package_name::function_name()`. 

As the name suggests, namespaces provide "spaces" for "names", it tells R exactly where to find a function. They provide a context for looking up the value of an object associated with a name. When we write `terra::vect()` we are asking R to look for the function `vect()` in the `terra` package.

This is a fairly advanced topic, and by-and-large, not that important! When you first start using namespaces, it'll seem like a lot of work for little gain. However, having a high quality namespace helps encapsulate your package and makes it self-contained. This ensures that other packages won't interfere with your code, that your code won't interfere with other packages, and that your package works regardless of the environment in which it's run.

You don't always need to write the namespace every time. A very common practice is to load the necessary packages at the beginning of your script (in the set up section for example) with `library()`. This is actually the most known and common approach. 

To do so just add `library(name_of_package)`, for example `library(terra)`. Then we can just call the function without the name space, like this `vect()`.

#### The assign operator

The assign operator `<-`. This is a peculiarity of R and it is used to assign values to variables. However, `<-` is preferred in R scripts because it makes assignments visually distinct from comparisons (`==`) and function arguments (`=`).

Note that the operators `<-` and `=` can be used, almost interchangeably. However, inside function calls, you should use `=` to name arguments.

#### Functions
In Stata, you're used to running do-files or programs to automate tasks. In R, functions play a similar role: they help you organize code and reuse it easily.

A function in R looks like this:
```{r fn_body}
#| labek: fn_body
#| eval: false

my_function <- function(input1, input2) {
  # Do something with the inputs
  result <- input1 + input2
  return(result)
}
```

* `my_function` is the function's name.

* `function(input1, input2)` defines what inputs (arguments) it takes.

* Inside `{}`, you write the code that runs when you call the function.

* `return(result)` tells R what the output should be.

You call the function like this:
```{r fn_out}
#| label: fn_out
#| eval: false

my_function(3, 5)
# Output: 8
```

Note that you can change the order of the inputs if you properly label them.
```{r fn_out2}
#| label: fn_out2
#| eval: false

my_function(input2 = 5, input1 = 3)
# Output: 8
```

Key points for Stata users:

* Functions in R must be assigned to a name using <- (the assignment operator).

* You can think of functions a little like Stata's program define, but in R, every function can return a value to be used later.

* You can nest functions inside other code, making your analysis scripts cleaner and easier to read.


### Want to know about the data?
#### Weather
Weather observation are obtained from ERA5-Land reanalysis dataset. H-TESSEL is the land surface model that is the basis of ERA5-Land. The data is a post-processed monthly-mean average of the original ERA5-Land dataset.

Total precipitation is the accumulated liquid and frozen water, including rain and snow, that falls to the Earth's surface. It is the sum of large-scale precipitation and convective precipitation. Precipitation variables do not include fog, dew or the precipitation that evaporates in the atmosphere before it lands at the surface of the Earth.

It is possible to find additional information [here](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=overview) and the related manual [here](https://confluence.ecmwf.int/display/CKB/ERA5-Land). 
The data can be freely download from [here](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=overview).


| Parameter           | Value                   |
|:--------------------|:-----------------------:|
| spatial resolution  | 0.1° x 0.1° lon lat     |
| temporal resolution | month                   |
| time frame          | Jan. 1950 - Dec. 2022   |
| unit of measure     | m                       |

