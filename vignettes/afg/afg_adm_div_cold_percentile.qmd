---
title: "Cold Percentiles in Afganistan Districts"
author: "JMR"
toc: true
toc-expand: 1
toc-depth: 2
format:
  html:
    self-contained: true
    code-tools: true
    toc-location: right-body
  docx: 
    toc-location: body
editor: source
editor_options:
  chunk_output_type: console
vignette: >
  %\VignetteIndexEntry{Vignette's Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
---

## Intro
The goal of this tutorial is to guide the user to calculate weather percentiles in given areas. In particular we will use temperature observations from ERA5-Land and the level two administrative divisions of Afghanistan.
There are two main approaches to do so. The first approach spatially average the weather observations within each area and then calculate the percentile. The second approach calculates the percentiles for each spatial points from the weather data. The first approach is faster as it requires less memory, but it is less accurate because it average the observations. Indeed, by averaging we smooth the distribution and we lessen the role of extreme weather realizations.

This tutorial will go with the second approach.

## Is this guide for me?

This guide provides a step-by-step approach to extract raster data based on survey locations. The target audience includes economists who may have experience with statistical software (e.g. STATA) but are less familiar with spatial data processing in R.

The document is not meant to be a course on R or on how the functions work. It is just a practice example on how to extract raster data based on coordinate location. This is done by using specific functions that wrap up as many steps as possible to ensure it is easier for the user to follow.

## Overview of Steps

In this guide, we will go through the following steps:

1.  Load the data
2.  Extract the weather values based on the administrative divisions
3.  Calculate the percentiles 
4.  Merge the percentiles with the administrative divisions
5.  Save the results for later use

## What do I need before starting?

The following R packages are necessary: `terra`, `tidyverse`, `haven`, `data.table`. To install the above package you can use `install.packages("name_of_package")`, don't forget the `"`. We also need the  package `climate4economist`, which can be installed only locally.

If you are not familiar with R check the [appendix] for understanding some coding style used in this tutorial.

## Code
### Set Up

In the setup, we create the paths to the various data sources and load the necessary functions for extraction. Note `..` means one step back to the folder directory, i.e. one folder back.

```{r set_up}
#| label: set_up
path_to_tmp_min <- file.path("..",
                             "data", "weather", "ERA5_Land", "AFG", "daily", 
                             "2m_temperature")

path_to_adm_div <- file.path("..",
                             "data", "adm_div", "UN_borders", "UN-AFG-ADM2.gpkg")
```

```{r package}
#| label: package

library(climatic4economist)
```

### Load the data
Let's start by loading the data into R. We load the weather observation with the function `terra::rast()`.

>We set the names of the layer as the date of observation. This is very important for later.

```{r read_weather}
#| label: read_weather

tmp_min_k <- list.files(path_to_tmp_min, full.names = TRUE) |>
  terra::rast()
tmp_min_k
names(tmp_min_k) <- terra::time(tmp_min_k)
tmp_min_k
```

We load the administrative divisions with the function `sf::st_read()` and we create a variable `ID_adm_div` that uniquely identifies the administrative divisions.

>It is very important to check if the spatial polygon and the raster data share the same coordinate reference system!

We can see that both uses the WGS 84 CRS.

```{r read_adm_div}
#| label: read_ad_div

adm_div <- sf::st_read(path_to_adm_div, quiet = TRUE) |>
  dplyr::mutate(ID_adm_div = as.character(1:dplyr::n()),
                .before = 1) |>
  dplyr::select(ID_adm_div, ADM1CD, ADM1NM, ADM2CD, ADM2NM)
adm_div
```

### Plot
A good practice is to plot the data to check that the different data speak to each other, i.e. they share the same CRS.

```{r plot}
#| label: plot

terra::plot(tmp_min_k, 1)
terra::lines(adm_div, col = "white")
```

Since the administrative divisions and the weather observations matches we can move on with the analysis.

### Extract
We now proceed with the extraction. The function `extract_by_poly()` just requires the weather observations and the administrative divisions.

The result shows the extracted weather in each administrative division identified by `ID_adm_div`, in wide format. Note that we have also the variable `x` and `y` which are the coordinates of the single weather observation that falls in the administrative division. Finally, the variable `coverage_fraction` tells how much of the weather observation fall within the division.

```{r extract}
#| label: extract

tmp_min_div_k <- extract_by_poly(tmp_min_k, adm_div)
tmp_min_div_k
```

### Transform variable
The original unit of measure of the temperature in Kelvin, we change it into Celsius.

```{r transformation}
#| label: transformation

tmp_min_div <- tmp_min_div_k |>
  dplyr::mutate(dplyr::across(.cols = dplyr::matches("[0-9]{4}"),
                              .fns = ~ .x - 273.15))
```

### Prepare data
Before calculating the percentile we select just the observations after 1980 with the function `select_by_dates()`. Indeed, 30 years is usually considered enough observation to evaluate climatic parameters, and weather observation before 1980 are considered less reliable.

Then we pass the data in the `prepare_coord()` which creates a variable `ID` for the unique location. This variable is crucial for the next steps.

Therefore, now we have a variable `ID` associated to the unique location identified by the `x` and `y` coordinates, and a variable `ID_adm_div` associated to the unique administrative divisions. Notice how the weather observation start from 1980.

```{r prepare_coord}
#| label: prepare_coord

tmp_min_div <- prepare_coord(tmp_min_div, lon_var = x, lat_var = y)

tmp_min_80 <- select_by_dates(tmp_min_div, from = "1980-01-01")
tmp_min_80 <- prepare_coord(tmp_min_80, lon_var = x, lat_var = y)
```

### Calculate percentiles
>If we believe the thresholds shouldn't be the same across all the location but instead be adaptive to the local long run climatic condition we should use the relative thresholds. In this case the thresholds varies for each location, adapting to the local climatic features and making the spatial comparison among heterogeneous places more meaningful. The relative approach measures the extreme weather events in term of their rarity, which is measured by the percentile of their local and seasonal distribution.

We now calculate the percentiles with the function `calc_pct_day()`. The functions requires the weather observations with the additional variable `ID` and the desired percentiles to be computed. 

We are interested in cold percentiles, therefore we calculate the extreme percentiles of the left tail.

Eventually, we could also have provided two additional arguments to the function. These are `l_thresh` and `u_thresh`, which removes the observations which are below the `l_thresh` or above `u_thresh`. For example, since we are looking for cold percentile we could have add `u_thresh = 0` to filter out all temperatures above zero degree Celsius and leave just the cold observations. This can be interpreted as an upper bound of the cold percentiles which will never be above the `u_thresh`.

```{r percentiles}
#| label: percentiles

tmp_min_pct <- calc_pct_day(tmp_min_80, p = c(0.01, 0.05, 0.1))

```

### Merge with administrative divisions 
To get the names of the administrative divisions with the associated percentiles we merge the result first with the `tmp_min_div` and then with `adm_div`. We need this double passage as `tmp_min_div` has the key to match the two dataset, namely `ID_adm_div`.

We see that we have all the information form the percentiles and the name of the administrative divisions.
```{r merge}
#| label: merge
tmp_min_pct_div <- merge_with_survey(tmp_min_div, tmp_min_pct) |>
  dplyr::full_join(sf::st_drop_geometry(adm_div), by = "ID_adm_div")

tmp_min_pct_div
```

### Write
As a final step we save the result for future calculation. Note that we maintain the original spatial resolution of the weather observations so that it doesn't affect the accuracy.

We save it as an `rds` object, which is the native R format. We do it as the next calculation will be in R and this format helps for the compression and reading of the data. However, if the data will be use in other software it is still possible to save in other format.  For example, `haven::write_dta()` for `dta` format or `data.table::fwrite()` for `csv`.

```{r write}
#| label: write

dplyr::full_join(sf::st_drop_geometry(adm_div), 
                 tmp_min_div, by = "ID_adm_div") |>
  dplyr::as_tibble() |>
  dplyr::relocate(ID_adm_div, ADM1CD, ADM1NM, ADM2CD, ADM2NM,
                  ID, x, y, coverage_fraction,
                  sort(colnames(tmp_min_div))) |>
  saveRDS(file = file.path("data", "weather", "ERA5_Land", "AFG", 
                           "daily",  "day_50_25_2m_tmp_min.rds"))

saveRDS(tmp_min_pct_div,
        file = file.path("data", "weather", "ERA5_Land", "AFG", 
                         "percentile",  "pct_80_25_2m_tmp_min.rds"))
```

## Conclusion
In this tutorial, we extract weather observations based on spatial polygons, specifically the administrative divisions of Afghanistan. We maintain the original spatial resolution of the weather observations. As a result, the output includes both an `ID` variable, which identifies each unique weather observation, and an `ID_adm_div` variable, which corresponds to the unique administrative divisions.

Multiple weather observations fall within each administrative division, each associated with a coverage fraction representing the actual area of the pixel within the division. We retain this level of detail to preserve spatial resolution for future calculations. Alternatively, we could aggregate all percentiles within each administrative division—weighted by their respective coverage fractions—to obtain a single percentile per division.


