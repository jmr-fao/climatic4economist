{"title":"Extract CHIRPS precipitation","markdown":{"yaml":{"title":"Extract CHIRPS precipitation","author":"JMR","toc":true,"toc-expand":1,"toc-depth":2,"format":{"html":{"self-contained":true,"code-tools":true,"toc-location":"right-body"},"docx":{"toc-location":"body"}},"editor":"source","editor_options":{"chunk_output_type":"console"},"vignette":"%\\VignetteIndexEntry{Vignette's Title} %\\VignetteEncoding{UTF-8} %\\VignetteEngine{quarto::html}\n"},"headingText":"Is this guide for me?","containsRefs":false,"markdown":"\n\n\nThis guide provides a step-by-step approach to extract raster data based on survey locations. The target audience includes economists who may have experience with statistical software (e.g. STATA) but are less familiar with spatial data processing in R.\n\nThe document is not meant to be a course on R or on how the functions work. It is just a practice example on how to extract raster data based on coordinate location. This is done by using specific functions that wrap up as many steps as possible to ensure it is easier for the user to follow.\n\nIn this example, we will extract the CHIRPS precipitation observations in Suriname, based on the centroids of the Principal Sampling Units (PSU) of the Suriname Survey of Living Conditions for the years 2016/17 and 2022.\n\n## Overview of Steps\n\nIn this guide, we will go through the following steps:\n\n1.  Load the data\n2.  Georeference the survey\n3.  Plot the data\n4.  Extract the raster values\n5.  Merge the extracted values with the survey\n6.  Save the results.\n\n## What do I need before starting?\n\nThe following R packages are necessary: `terra`, `tidyverse`, `haven`, and script `functions.R`, which contain the wrapped specific functions. To install the above package you can use `install.packages(\"name_of_package\")`, don't forget the `\"`.\n\nIf you are not familiar with R check the [appendix] for understanding some coding style used in this tutorial.\n\n# Code\n\n## Set Up\n\nIn the setup, we create the paths to the various data sources and load the necessary functions for extraction. Note `..` means one step back to the folder directory, i.e. one folder back.\n\n```{r set_up}\n#| label: set_up\n\n# paths\npath_to_data_raw <- file.path(\"..\",\n                              \"data\")\n\npath_to_wave_1 <- file.path(path_to_data_raw, \"survey\", \"surname\", \"wave 1\",\n                            \"RT001_Public.dta\")\n\npath_to_wave_2 <- file.path(path_to_data_raw, \"survey\", \"surname\", \"wave 2\", \n                            \"2022 RT001_Housing_plus.dta\")\n\npath_to_adm_div_0 <- file.path(path_to_data_raw, \"adm_div\", \"geoBoundaries\",\n                               \"geoBoundaries-SUR-ADM0.geojson\")\n\npath_to_pre_monthly <- file.path(path_to_data_raw, \"weather\", \"CHIRPS\", \"monthly\",\n                                 \"chirps-v2.0.monthly.nc\")\n\npath_to_pre_daily <- file.path(path_to_data_raw, \"weather\", \"CHIRPS\", \"daily\")\n\npath_to_survey_day_pre <- file.path(path_to_data_raw, \"result\", \"sur_pre_day_hh.dta\")\n\npath_to_survey_month_pre <- file.path(path_to_data_raw, \"sur_pre_mnth_hh.dta\")\n```\n\n\n```{r load_packg}\n#| label:  load_packg\n\nlibrary(climatic4economist)\n```\n\n## Load the data\n\nWe begin by reading the surveys, which in this case consist of two waves with potentially different locations. As a result, we need to load both waves. The waves are stored as `dta` files, so we use the `haven::read_dta()` function to read them.\n\nWe only need the hhid, the survey coordinates, and the interview dates. We use `dplyr::select()` to choose these variables. This passage is optional and we bring with us all the variables, but we won't use them. Note that the first wave does not include the interview date.\n\nWe combine the two waves using `dplyr::bind_rows()`.\n\nWe can use the `head()` function to preview the data and see how it looks.\n\n```{r read_surveys}\n#| label: read_surveys\n\nwave_1 <- haven::read_dta(path_to_wave_1) |>\n    dplyr::select(hhid, lat_cen, long_cen) |> \n    dplyr::mutate(wave = 1)\n\nwave_2 <- haven::read_dta(path_to_wave_2) |>\n    dplyr::select(hhid, end_date_n, lat_cen, long_cen) |>\n    dplyr::mutate(wave = 2)\n\nsurvey <- dplyr::bind_rows(wave_1, wave_2)\n\nhead(survey)\n```\n\nWe also read the spatial file containing the national borders of Suriname, we use `terra::vect()` to load it. By printing the spatial data, we can obtain key information, such as the dimensions (number of rows and variables), the geometry (which indicates the type of spatial object), and the coordinate reference system (CRS), which links the coordinates to precise locations on the Earth's surface. The CRS is particularly important when working with different spatial datasets, as mismatched CRSs can prevent the datasets from aligning correctly.\n\n```{r read_adm_div}\n#| label: read_adm_div\n\nadm_div_0 <- terra::vect(path_to_adm_div_0)\nadm_div_0\n```\n\nFinally, we load the precipitation data. Climatic data typically comes in the form of raster data. A raster represents a two-dimensional image as a rectangular matrix or grid of pixels. These are spatial rasters because they are georeferenced, meaning each pixel (or \"cell\" in GIS terms) represents a square region of geographic space. The value of each cell reflects a measurable property (either qualitative or quantitative) of that region. In this case, the values are monthly precipitation that falt inn that region. We use the function `terra::rast()` to load the raster data.\n\nThis particular raster has global coverage, so we crop it to focus on the country area to reduce its size. Although this step is not strictly necessary, it helps decrease the memory load and makes visualizations more manageable. We use the function `terra::crop()` for this purpose.\n\nWhen we print the raster, we obtain several key details. The dimension tells us how many cells the raster consists of and the number of layers, each layer corresponds to a particular months for which the observations were made. We also get the spatial resolution, which defines the size of each square region in geographic space, and the coordinate reference system (CRS). Given the importance of the CRS, we extract it using `terra::crs()` and save it for later use.\n\nWe also rename the raster layers to reflect the corresponding dates for each layer, as this is useful if we want to track the dates. We use `terra::time()` to extract the dates.\n\n> Note that rasters can store time information in different ways, so it may not always be possible to retrieve dates in this manner. A common alternative is for dates to be embedded in the layer names, in which case we wouldnâ€™t need to rename the layers.\n\n```{r read_pre_monthly}\n#| label: read_pre_monthly\n\nweather_monthly <- terra::rast(path_to_pre_monthly) |>\n    terra::crop(adm_div_0)\nweather_monthly\n\nnames(weather_monthly) <- terra::time(weather_monthly)\nweather_monthly\n```\n\nWe replicate for daily observation. Since the daily files are bigger, it is more likely to obtain the data separated in multiple file. Usually, each file is one year of observations. We have daily observation from 1980 to 2024, divided into five files. To read them all we just need to provide to the `terra::rast()` function the directories of all the files, the function combines them together for us.\n\n```{r read_pre_daily}\n#| label: read_pre_daily\n\nlist.files(path_to_pre_daily) \n\nweather_daily <- list.files(path_to_pre_daily, full.names = TRUE) |>\n  terra::rast() |>\n  terra::crop(adm_div_0)\nweather_daily\n\nnames(weather_daily) <- terra::time(weather_daily)\nweather_daily\n```\n\n## Georeference the survey\n\nAs we've mentioned, the weather data is georeferenced, so we need to ensure the same for the survey data. Since many households share the same coordinates, they are linked to the same weather events. To reduce computation time, we extract data only for the unique coordinates, rather than for each household. Moreover, we must ensure that we can later associate the correct weather data with the right household, we do this by creating an merging variable called `ID`.\n\nThis is handled by the `prepare_coord()` function, which requires the coordinates' variable names as input.\n\nOnce we have the unique coordinates, we are ready to transform them into spatial points using the `georef_coord()` function. When performing this transformation, it's crucial to set the correct CRS, which must match that of the weather data. The CRS is provided as an argument of the function, using the previously saved CRS from the weather data. Also the `georef_coord()` function requires the coordinates' variable names as input.\n\nWe can print the result to check the transformation. The new column, `ID`, is created by `prepare_coord()` and identifies each unique coordinate. This is used to merge the weather data with the household data.\n\n```{r georef_coord}\n#| label: georef_coord\ncoord <- prepare_coord(survey, lat_var = lat_cen, lon_var = long_cen)\n\ncoord_geo <- georef_coord(coord,\n                          geom = c(\"long_cen\", \"lat_cen\"),\n                          crs = \"EPSG:4326\")\ncoord_geo\n```\n\nNote how there are `r nrow(coord_geo)` rows. These are the unique locations from the survey.\n\n## Plot\n\nA good practice when working with spatial data is to plot it. This is the best way to verify that everything is working as expected.\n\nFirst, we plot the survey coordinates to ensure they are correctly located within the country and to examine their spatial distribution.\n\n```{r plot_survey_geo}\n#| label: plot_survey_geo\n\nterra::plot(adm_div_0, col = \"grey\", main = \"Suriname and PSU centroids\")\nterra::points(coord_geo, col = \"gold\", alpha = 0.5, cex = 0.5)\n\n```\n\nWe confirm that the survey locations are within the country borders, which is great! We also observe that the spatial distribution of survey coordinates is neither random nor uniform; most are concentrated near the capital and along the coast.\n\nNext, we plot a layer of the precipitation data to see how it overlaps with the spatial coordinates.\n\n```{r plot_precipitation}\n#| label: plot_precipitation\n\nterra::plot(weather_monthly, \"2024-10-01\", col = terra::map.pal(\"water\"),\n            main = \"Monthly precipitation at 2024-10 and survey location\")\nterra::lines(adm_div_0, col = \"white\", lwd = 2)\nterra::points(coord_geo, col = \"gold\", alpha = 0.5, cex = 0.5)\n```\n\nOnce again, the survey coordinates align with the precipitation data, which is great! We can also observe the high spatial resolution of the CHIRPS dataset. However, despite this high resolution, some survey coordinates still fall within the same cell.\n\n## Extract\n\nNext, we extract the weather data based on the survey coordinates using the `extract_by_coord()` function. This function requires the raster with the weather data and the georeferenced coordinates as inputs.\n\nLooking at the result, we see first the `ID` column, that identifies the unique survey coordinates. The second and third column are the coordinates of the cells. The other columns contain the weather observations over time specific to each coordinate.\n\n```{r extract_precipitation}\n#| label: extract_precipitation\n\npre_month_coord <- extract_by_coord(raster = weather_monthly, \n                                    coord = coord_geo)\npre_month_coord\n\npre_daily_coord <- extract_by_coord(raster = weather_daily, \n                                    coord = coord_geo)\npre_daily_coord\n```\n\nAgain we have a row for each unique location from the survey. However, if we want to know how many different cells there are we can look unique cell coordinates.\n\n```{r cell_coordinate}\n#| label: cell_coordinate\n\nunique_cell <- pre_month_coord |>\n  dplyr::distinct(x_cell, y_cell)\nnrow(unique_cell)\n```\n\nWe see that now the number of rows is `r nrow(unique_cell)`, this is the actual different weather observation that we can merge with the survey.\n\n## Merge with survey\n\nNow, we combine the extracted weather data with the survey data using `merge_with_survey()`, which under the hood uses the variable `ID` as the key matching variable.\n\n```{r merge_pre}\n#| label: merge_pre\n\npre_month_survey <- merge_with_survey(coord, pre_month_coord)\npre_month_survey\n\npre_day_survey <- merge_with_survey(coord, pre_daily_coord)\npre_day_survey\n```\n\nWe are back at `r nrow(pre_month_survey)`, which matches the original survey.\n\n## Save\n\nThe final step of the code is to save the result. In this case, we save it as a `dta` file using the `haven::write_dta()` function.\n\n```{r write_data}\n#| label: write_data\n\nhaven::write_dta(pre_month_survey, path_to_survey_month_pre)\nhaven::write_dta(pre_day_survey, path_to_survey_day_pre)\n```\n\n# Take home messages\n\n1.  Load! `haven::read_dta()` for the `dta` files, `terra::vect()` for the spatial vectors file, `terra::rast()` for the raster files.\n\n2.  Georeference! Use the wrapper functions `prepare_coord()` and `georef_coord()`. Remember to plot the result for confirmation.\n\n3.  Extract! Use the wrapper function `extract_by_coord()`.\n\n4.  Merge! Use the wrapper function `merge_with_survey()`.\n\n5.  Save! If in a `dta` file use `haven::write_dta()`.\n\n# Appendix\n\n## New to R? Read this first!\n\n### The pipe command\n\nThe pipe command `|>`. It lets you pass the result of one expression as the first argument to the next, creating a fluid chain of functions.\n\n### The package namespaces\n\nThe package namespaces `package_name::function_name()`. As the name suggests, namespaces provide \"spaces\" for \"names\". They provide a context for looking up the value of an object associated with a name. When we write `terra::vect()` we are asking R to look for the function `vect()` in the `terra` package.\n\nIt's a fairly advanced topic, and by-and-large, not that important! When you first start using namespaces, it'll seem like a lot of work for little gain. However, having a high quality namespace helps encapsulate your package and makes it self-contained. This ensures that other packages won't interfere with your code, that your code won't interfere with other packages, and that your package works regardless of the environment in which it's run.\n\nYou can avoid using every time the name space by just loading the necessary packages at the beginning of the code (in the set up section for example). This is the most known and common approach. To do so just add `library(name_of_package)`, for example `library(terra)`. Then we can just call the function without the name space, like this `vect()`.\n\n### The assign operator\n\nThe assign operator `<-`. This is a peculiarity of R and it is used to assign values to variables. Note that the operators `<-` and `=` can be used, almost interchangeably.\n\n## Want to know about the data?\n\n### Precipitation\n\nMonthly and daily precipitation from Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS)[^1] is a 35+ year quasi-global rainfall data set. Spanning 50Â°S-50Â°N (and all longitudes) and ranging from 1981 to near-present, CHIRPS incorporates in-house climatology, CHPclim, 0.05Â° resolution satellite imagery, and in-situ station data to create gridded rainfall time series for trend analysis and seasonal drought monitoring.\n\n[^1]: Funk, C.C., Peterson, P.J., Landsfeld, M.F., Pedreros, D.H., Verdin, J.P., Rowland, J.D., Romero, B.E., Husak, G.J., Michaelsen, J.C., and Verdin, A.P., 2014, A quasi-global precipitation time series for drought monitoring: U.S. Geological Survey Data Series 832, 4 p. http://pubs.usgs.gov/ds/832/\n\nData can be downloaded from [here](https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_monthly/netcdf/) while extra information are available [here](https://www.chc.ucsb.edu/).\n\n| feature             | value                 |\n|:--------------------|:----------------------|\n| spatial resolution  | 0.05 x 0.05 (\\~ 5 km) |\n| temporal resolution | monthly or daily      |\n| temporal frame      | 1981 - near present   |\n| unit of measure     | mm/month or mm/day    |\n\n### Surveys\n\nSuriname Survey of Living Conditions. The 2022 Suriname Survey of Living Conditions is a joint survey made by The Inter-American Development Bank (IDB) and the World Bank. The 2022 Suriname Survey of Living Conditions - administered to a nationally representative sample, which included 7,713 individuals from 2,540 households - was developed to support poverty analysis as well as policy planning and is a helpful tool for policy makers to facilitate fact-based decision making. The surveyâ€™s design and execution were financed by the IDB, while the World Bank and IDB are joining forces to analyze data and produce initial findings.\n\nThe Suriname Survey of Living Conditions (SSLC) 2016/17 is an effort of the Inter-American Development Bank (IDB) with the support of the EnergieBedrijvan Surinameâ€™s (state-owned electrical company of Suriname) and the Central Bank of Suriname. It visited about 2,000 households from October 2016 through September 2017 and collected data on the most important dimensions of welfare, which will support evidence-based policy making in areas such as education, health, housing, employment and poverty alleviation. The survey also gathered information on the consumption patterns, income and expenditures of the Surinamese households, intended to update the Consumption Price Index basket and inform the System of National Accounts.\n\nFor extra info look [here](https://openknowledge.worldbank.org/entities/publication/2d0e6975-2f85-4d12-83fa-4f75c617cf89) and [here](https://webapps.ilo.org/surveyLib/index.php/catalog/7499).\n\n### National boundaries\n\nThe national administrative divisions are obtained from GeoBoundaries[^2]. GeoBoundaries Built by the community and William & Mary geoLab, the geoBoundaries Global Database of Political Administrative Boundaries Database is an online, open license (CC BY 4.0) resource of information on administrative boundaries (i.e., state, county) for every country in the world. Since 2016, we have tracked approximately 1 million boundaries within over 200 entities, including all UN member states.\n\n[^2]: Runfola D, Anderson A, Baier H, Crittenden M, Dowker E, Fuhrig S, et al. (2020) geoBoundaries: A global database of political administrative boundaries. PLoS ONE 15(4): e0231866. https://doi.org/10.1371/journal.pone.0231866.\n\nData can be downloaded from [here](https://www.geoboundaries.org) while extra information are available [here](https://www.geoboundaries.org/countryDownloads.html).\n","srcMarkdownNoYaml":"\n\n## Is this guide for me?\n\nThis guide provides a step-by-step approach to extract raster data based on survey locations. The target audience includes economists who may have experience with statistical software (e.g. STATA) but are less familiar with spatial data processing in R.\n\nThe document is not meant to be a course on R or on how the functions work. It is just a practice example on how to extract raster data based on coordinate location. This is done by using specific functions that wrap up as many steps as possible to ensure it is easier for the user to follow.\n\nIn this example, we will extract the CHIRPS precipitation observations in Suriname, based on the centroids of the Principal Sampling Units (PSU) of the Suriname Survey of Living Conditions for the years 2016/17 and 2022.\n\n## Overview of Steps\n\nIn this guide, we will go through the following steps:\n\n1.  Load the data\n2.  Georeference the survey\n3.  Plot the data\n4.  Extract the raster values\n5.  Merge the extracted values with the survey\n6.  Save the results.\n\n## What do I need before starting?\n\nThe following R packages are necessary: `terra`, `tidyverse`, `haven`, and script `functions.R`, which contain the wrapped specific functions. To install the above package you can use `install.packages(\"name_of_package\")`, don't forget the `\"`.\n\nIf you are not familiar with R check the [appendix] for understanding some coding style used in this tutorial.\n\n# Code\n\n## Set Up\n\nIn the setup, we create the paths to the various data sources and load the necessary functions for extraction. Note `..` means one step back to the folder directory, i.e. one folder back.\n\n```{r set_up}\n#| label: set_up\n\n# paths\npath_to_data_raw <- file.path(\"..\",\n                              \"data\")\n\npath_to_wave_1 <- file.path(path_to_data_raw, \"survey\", \"surname\", \"wave 1\",\n                            \"RT001_Public.dta\")\n\npath_to_wave_2 <- file.path(path_to_data_raw, \"survey\", \"surname\", \"wave 2\", \n                            \"2022 RT001_Housing_plus.dta\")\n\npath_to_adm_div_0 <- file.path(path_to_data_raw, \"adm_div\", \"geoBoundaries\",\n                               \"geoBoundaries-SUR-ADM0.geojson\")\n\npath_to_pre_monthly <- file.path(path_to_data_raw, \"weather\", \"CHIRPS\", \"monthly\",\n                                 \"chirps-v2.0.monthly.nc\")\n\npath_to_pre_daily <- file.path(path_to_data_raw, \"weather\", \"CHIRPS\", \"daily\")\n\npath_to_survey_day_pre <- file.path(path_to_data_raw, \"result\", \"sur_pre_day_hh.dta\")\n\npath_to_survey_month_pre <- file.path(path_to_data_raw, \"sur_pre_mnth_hh.dta\")\n```\n\n\n```{r load_packg}\n#| label:  load_packg\n\nlibrary(climatic4economist)\n```\n\n## Load the data\n\nWe begin by reading the surveys, which in this case consist of two waves with potentially different locations. As a result, we need to load both waves. The waves are stored as `dta` files, so we use the `haven::read_dta()` function to read them.\n\nWe only need the hhid, the survey coordinates, and the interview dates. We use `dplyr::select()` to choose these variables. This passage is optional and we bring with us all the variables, but we won't use them. Note that the first wave does not include the interview date.\n\nWe combine the two waves using `dplyr::bind_rows()`.\n\nWe can use the `head()` function to preview the data and see how it looks.\n\n```{r read_surveys}\n#| label: read_surveys\n\nwave_1 <- haven::read_dta(path_to_wave_1) |>\n    dplyr::select(hhid, lat_cen, long_cen) |> \n    dplyr::mutate(wave = 1)\n\nwave_2 <- haven::read_dta(path_to_wave_2) |>\n    dplyr::select(hhid, end_date_n, lat_cen, long_cen) |>\n    dplyr::mutate(wave = 2)\n\nsurvey <- dplyr::bind_rows(wave_1, wave_2)\n\nhead(survey)\n```\n\nWe also read the spatial file containing the national borders of Suriname, we use `terra::vect()` to load it. By printing the spatial data, we can obtain key information, such as the dimensions (number of rows and variables), the geometry (which indicates the type of spatial object), and the coordinate reference system (CRS), which links the coordinates to precise locations on the Earth's surface. The CRS is particularly important when working with different spatial datasets, as mismatched CRSs can prevent the datasets from aligning correctly.\n\n```{r read_adm_div}\n#| label: read_adm_div\n\nadm_div_0 <- terra::vect(path_to_adm_div_0)\nadm_div_0\n```\n\nFinally, we load the precipitation data. Climatic data typically comes in the form of raster data. A raster represents a two-dimensional image as a rectangular matrix or grid of pixels. These are spatial rasters because they are georeferenced, meaning each pixel (or \"cell\" in GIS terms) represents a square region of geographic space. The value of each cell reflects a measurable property (either qualitative or quantitative) of that region. In this case, the values are monthly precipitation that falt inn that region. We use the function `terra::rast()` to load the raster data.\n\nThis particular raster has global coverage, so we crop it to focus on the country area to reduce its size. Although this step is not strictly necessary, it helps decrease the memory load and makes visualizations more manageable. We use the function `terra::crop()` for this purpose.\n\nWhen we print the raster, we obtain several key details. The dimension tells us how many cells the raster consists of and the number of layers, each layer corresponds to a particular months for which the observations were made. We also get the spatial resolution, which defines the size of each square region in geographic space, and the coordinate reference system (CRS). Given the importance of the CRS, we extract it using `terra::crs()` and save it for later use.\n\nWe also rename the raster layers to reflect the corresponding dates for each layer, as this is useful if we want to track the dates. We use `terra::time()` to extract the dates.\n\n> Note that rasters can store time information in different ways, so it may not always be possible to retrieve dates in this manner. A common alternative is for dates to be embedded in the layer names, in which case we wouldnâ€™t need to rename the layers.\n\n```{r read_pre_monthly}\n#| label: read_pre_monthly\n\nweather_monthly <- terra::rast(path_to_pre_monthly) |>\n    terra::crop(adm_div_0)\nweather_monthly\n\nnames(weather_monthly) <- terra::time(weather_monthly)\nweather_monthly\n```\n\nWe replicate for daily observation. Since the daily files are bigger, it is more likely to obtain the data separated in multiple file. Usually, each file is one year of observations. We have daily observation from 1980 to 2024, divided into five files. To read them all we just need to provide to the `terra::rast()` function the directories of all the files, the function combines them together for us.\n\n```{r read_pre_daily}\n#| label: read_pre_daily\n\nlist.files(path_to_pre_daily) \n\nweather_daily <- list.files(path_to_pre_daily, full.names = TRUE) |>\n  terra::rast() |>\n  terra::crop(adm_div_0)\nweather_daily\n\nnames(weather_daily) <- terra::time(weather_daily)\nweather_daily\n```\n\n## Georeference the survey\n\nAs we've mentioned, the weather data is georeferenced, so we need to ensure the same for the survey data. Since many households share the same coordinates, they are linked to the same weather events. To reduce computation time, we extract data only for the unique coordinates, rather than for each household. Moreover, we must ensure that we can later associate the correct weather data with the right household, we do this by creating an merging variable called `ID`.\n\nThis is handled by the `prepare_coord()` function, which requires the coordinates' variable names as input.\n\nOnce we have the unique coordinates, we are ready to transform them into spatial points using the `georef_coord()` function. When performing this transformation, it's crucial to set the correct CRS, which must match that of the weather data. The CRS is provided as an argument of the function, using the previously saved CRS from the weather data. Also the `georef_coord()` function requires the coordinates' variable names as input.\n\nWe can print the result to check the transformation. The new column, `ID`, is created by `prepare_coord()` and identifies each unique coordinate. This is used to merge the weather data with the household data.\n\n```{r georef_coord}\n#| label: georef_coord\ncoord <- prepare_coord(survey, lat_var = lat_cen, lon_var = long_cen)\n\ncoord_geo <- georef_coord(coord,\n                          geom = c(\"long_cen\", \"lat_cen\"),\n                          crs = \"EPSG:4326\")\ncoord_geo\n```\n\nNote how there are `r nrow(coord_geo)` rows. These are the unique locations from the survey.\n\n## Plot\n\nA good practice when working with spatial data is to plot it. This is the best way to verify that everything is working as expected.\n\nFirst, we plot the survey coordinates to ensure they are correctly located within the country and to examine their spatial distribution.\n\n```{r plot_survey_geo}\n#| label: plot_survey_geo\n\nterra::plot(adm_div_0, col = \"grey\", main = \"Suriname and PSU centroids\")\nterra::points(coord_geo, col = \"gold\", alpha = 0.5, cex = 0.5)\n\n```\n\nWe confirm that the survey locations are within the country borders, which is great! We also observe that the spatial distribution of survey coordinates is neither random nor uniform; most are concentrated near the capital and along the coast.\n\nNext, we plot a layer of the precipitation data to see how it overlaps with the spatial coordinates.\n\n```{r plot_precipitation}\n#| label: plot_precipitation\n\nterra::plot(weather_monthly, \"2024-10-01\", col = terra::map.pal(\"water\"),\n            main = \"Monthly precipitation at 2024-10 and survey location\")\nterra::lines(adm_div_0, col = \"white\", lwd = 2)\nterra::points(coord_geo, col = \"gold\", alpha = 0.5, cex = 0.5)\n```\n\nOnce again, the survey coordinates align with the precipitation data, which is great! We can also observe the high spatial resolution of the CHIRPS dataset. However, despite this high resolution, some survey coordinates still fall within the same cell.\n\n## Extract\n\nNext, we extract the weather data based on the survey coordinates using the `extract_by_coord()` function. This function requires the raster with the weather data and the georeferenced coordinates as inputs.\n\nLooking at the result, we see first the `ID` column, that identifies the unique survey coordinates. The second and third column are the coordinates of the cells. The other columns contain the weather observations over time specific to each coordinate.\n\n```{r extract_precipitation}\n#| label: extract_precipitation\n\npre_month_coord <- extract_by_coord(raster = weather_monthly, \n                                    coord = coord_geo)\npre_month_coord\n\npre_daily_coord <- extract_by_coord(raster = weather_daily, \n                                    coord = coord_geo)\npre_daily_coord\n```\n\nAgain we have a row for each unique location from the survey. However, if we want to know how many different cells there are we can look unique cell coordinates.\n\n```{r cell_coordinate}\n#| label: cell_coordinate\n\nunique_cell <- pre_month_coord |>\n  dplyr::distinct(x_cell, y_cell)\nnrow(unique_cell)\n```\n\nWe see that now the number of rows is `r nrow(unique_cell)`, this is the actual different weather observation that we can merge with the survey.\n\n## Merge with survey\n\nNow, we combine the extracted weather data with the survey data using `merge_with_survey()`, which under the hood uses the variable `ID` as the key matching variable.\n\n```{r merge_pre}\n#| label: merge_pre\n\npre_month_survey <- merge_with_survey(coord, pre_month_coord)\npre_month_survey\n\npre_day_survey <- merge_with_survey(coord, pre_daily_coord)\npre_day_survey\n```\n\nWe are back at `r nrow(pre_month_survey)`, which matches the original survey.\n\n## Save\n\nThe final step of the code is to save the result. In this case, we save it as a `dta` file using the `haven::write_dta()` function.\n\n```{r write_data}\n#| label: write_data\n\nhaven::write_dta(pre_month_survey, path_to_survey_month_pre)\nhaven::write_dta(pre_day_survey, path_to_survey_day_pre)\n```\n\n# Take home messages\n\n1.  Load! `haven::read_dta()` for the `dta` files, `terra::vect()` for the spatial vectors file, `terra::rast()` for the raster files.\n\n2.  Georeference! Use the wrapper functions `prepare_coord()` and `georef_coord()`. Remember to plot the result for confirmation.\n\n3.  Extract! Use the wrapper function `extract_by_coord()`.\n\n4.  Merge! Use the wrapper function `merge_with_survey()`.\n\n5.  Save! If in a `dta` file use `haven::write_dta()`.\n\n# Appendix\n\n## New to R? Read this first!\n\n### The pipe command\n\nThe pipe command `|>`. It lets you pass the result of one expression as the first argument to the next, creating a fluid chain of functions.\n\n### The package namespaces\n\nThe package namespaces `package_name::function_name()`. As the name suggests, namespaces provide \"spaces\" for \"names\". They provide a context for looking up the value of an object associated with a name. When we write `terra::vect()` we are asking R to look for the function `vect()` in the `terra` package.\n\nIt's a fairly advanced topic, and by-and-large, not that important! When you first start using namespaces, it'll seem like a lot of work for little gain. However, having a high quality namespace helps encapsulate your package and makes it self-contained. This ensures that other packages won't interfere with your code, that your code won't interfere with other packages, and that your package works regardless of the environment in which it's run.\n\nYou can avoid using every time the name space by just loading the necessary packages at the beginning of the code (in the set up section for example). This is the most known and common approach. To do so just add `library(name_of_package)`, for example `library(terra)`. Then we can just call the function without the name space, like this `vect()`.\n\n### The assign operator\n\nThe assign operator `<-`. This is a peculiarity of R and it is used to assign values to variables. Note that the operators `<-` and `=` can be used, almost interchangeably.\n\n## Want to know about the data?\n\n### Precipitation\n\nMonthly and daily precipitation from Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS)[^1] is a 35+ year quasi-global rainfall data set. Spanning 50Â°S-50Â°N (and all longitudes) and ranging from 1981 to near-present, CHIRPS incorporates in-house climatology, CHPclim, 0.05Â° resolution satellite imagery, and in-situ station data to create gridded rainfall time series for trend analysis and seasonal drought monitoring.\n\n[^1]: Funk, C.C., Peterson, P.J., Landsfeld, M.F., Pedreros, D.H., Verdin, J.P., Rowland, J.D., Romero, B.E., Husak, G.J., Michaelsen, J.C., and Verdin, A.P., 2014, A quasi-global precipitation time series for drought monitoring: U.S. Geological Survey Data Series 832, 4 p. http://pubs.usgs.gov/ds/832/\n\nData can be downloaded from [here](https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_monthly/netcdf/) while extra information are available [here](https://www.chc.ucsb.edu/).\n\n| feature             | value                 |\n|:--------------------|:----------------------|\n| spatial resolution  | 0.05 x 0.05 (\\~ 5 km) |\n| temporal resolution | monthly or daily      |\n| temporal frame      | 1981 - near present   |\n| unit of measure     | mm/month or mm/day    |\n\n### Surveys\n\nSuriname Survey of Living Conditions. The 2022 Suriname Survey of Living Conditions is a joint survey made by The Inter-American Development Bank (IDB) and the World Bank. The 2022 Suriname Survey of Living Conditions - administered to a nationally representative sample, which included 7,713 individuals from 2,540 households - was developed to support poverty analysis as well as policy planning and is a helpful tool for policy makers to facilitate fact-based decision making. The surveyâ€™s design and execution were financed by the IDB, while the World Bank and IDB are joining forces to analyze data and produce initial findings.\n\nThe Suriname Survey of Living Conditions (SSLC) 2016/17 is an effort of the Inter-American Development Bank (IDB) with the support of the EnergieBedrijvan Surinameâ€™s (state-owned electrical company of Suriname) and the Central Bank of Suriname. It visited about 2,000 households from October 2016 through September 2017 and collected data on the most important dimensions of welfare, which will support evidence-based policy making in areas such as education, health, housing, employment and poverty alleviation. The survey also gathered information on the consumption patterns, income and expenditures of the Surinamese households, intended to update the Consumption Price Index basket and inform the System of National Accounts.\n\nFor extra info look [here](https://openknowledge.worldbank.org/entities/publication/2d0e6975-2f85-4d12-83fa-4f75c617cf89) and [here](https://webapps.ilo.org/surveyLib/index.php/catalog/7499).\n\n### National boundaries\n\nThe national administrative divisions are obtained from GeoBoundaries[^2]. GeoBoundaries Built by the community and William & Mary geoLab, the geoBoundaries Global Database of Political Administrative Boundaries Database is an online, open license (CC BY 4.0) resource of information on administrative boundaries (i.e., state, county) for every country in the world. Since 2016, we have tracked approximately 1 million boundaries within over 200 entities, including all UN member states.\n\n[^2]: Runfola D, Anderson A, Baier H, Crittenden M, Dowker E, Fuhrig S, et al. (2020) geoBoundaries: A global database of political administrative boundaries. PLoS ONE 15(4): e0231866. https://doi.org/10.1371/journal.pone.0231866.\n\nData can be downloaded from [here](https://www.geoboundaries.org) while extra information are available [here](https://www.geoboundaries.org/countryDownloads.html).\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"self-contained":true,"output-file":"sur_extract_chirps.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","author":"JMR","toc-expand":1,"logo":"../images/Climat4Economist_Symbol.png","editor":"source","editor_options":{"chunk_output_type":"console"},"vignette":"%\\VignetteIndexEntry{Vignette's Title} %\\VignetteEncoding{UTF-8} %\\VignetteEngine{quarto::html}\n","toc-location":"right-body","title":"Extract CHIRPS precipitation"},"extensions":{"book":{"multiFile":true}}},"docx":{"identifier":{"display-name":"MS Word","target-format":"docx","base-format":"docx"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"docx","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"page-width":6.5},"pandoc":{"default-image-extension":"png","to":"docx","toc":true,"toc-depth":2,"output-file":"sur_extract_chirps.docx"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"author":"JMR","toc-expand":1,"logo":"../images/Climat4Economist_Symbol.png","editor":"source","editor_options":{"chunk_output_type":"console"},"vignette":"%\\VignetteIndexEntry{Vignette's Title} %\\VignetteEncoding{UTF-8} %\\VignetteEngine{quarto::html}\n","toc-location":"body","title":"Extract CHIRPS precipitation"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","docx"]}